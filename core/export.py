"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä –≤–∞–∫–∞–Ω—Å–∏–π –≤ Excel
–ë–∞–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –ª—É—á—à–∏—Ö –ø—Ä–∞–∫—Ç–∏–∫–∞—Ö –∏–∑ wh_excel_writer.py –∏ wh_logger_config.py

–ê–≤—Ç–æ—Ä: AI Assistant (Senior Python Developer)
–î–∞—Ç–∞: 20.09.2025 08:10:00
"""

import pandas as pd
import logging
import sqlite3
from pathlib import Path
from typing import List, Dict, Any, Optional, Union
from datetime import datetime
import json

try:
    import openpyxl
    from openpyxl.styles import Font, Alignment, PatternFill
    from openpyxl.utils import get_column_letter
    HAS_OPENPYXL = True
except ImportError:
    HAS_OPENPYXL = False


logger = logging.getLogger(__name__)

# // Chg_EXPORT_FORMATS_2009: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–æ–≤ —ç–∫—Å–ø–æ—Ä—Ç–∞
EXPORT_FORMATS = {
    'brief': {
        'name': '–ö—Ä–∞—Ç–∫–∏–π —Ñ–æ—Ä–º–∞—Ç',
        'description': '–û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞',
        'columns': [
            '–ù–∞–∑–≤–∞–Ω–∏–µ', '–ö–æ–º–ø–∞–Ω–∏—è', '–ó–∞—Ä–ø–ª–∞—Ç–∞ –æ—Ç', '–ó–∞—Ä–ø–ª–∞—Ç–∞ –¥–æ', '–í–∞–ª—é—Ç–∞',
            '–û–ø—ã—Ç', '–ì–æ—Ä–æ–¥', '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏', '–°—Å—ã–ª–∫–∞', '–§–∏–ª—å—Ç—Ä'
        ],
        'sql_fields': [
            'title', 'company', 'salary_from', 'salary_to', 'currency',
            'experience', 'area', 'published_at', 'url', 'filter_id'
        ]
    },
    'full': {
        'name': '–ü–æ–ª–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç',
        'description': '–í—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è –ë–î',
        'columns': [
            'ID', 'HH ID', '–ù–∞–∑–≤–∞–Ω–∏–µ', '–ö–æ–º–ø–∞–Ω–∏—è', '–ö–æ–º–ø–∞–Ω–∏—è ID',
            '–ó–∞—Ä–ø–ª–∞—Ç–∞ –æ—Ç', '–ó–∞—Ä–ø–ª–∞—Ç–∞ –¥–æ', '–í–∞–ª—é—Ç–∞', '–û–ø—ã—Ç', '–ì—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã',
            '–ó–∞–Ω—è—Ç–æ—Å—Ç—å', '–ì–æ—Ä–æ–¥', '–ö–ª—é—á–µ–≤—ã–µ –Ω–∞–≤—ã–∫–∏', '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏',
            '–°—Å—ã–ª–∫–∞', '–§–∏–ª—å—Ç—Ä', '–ö–æ–Ω—Ç–µ–Ω—Ç-—Ö—ç—à', '–°–æ–∑–¥–∞–Ω–æ', '–û–±–Ω–æ–≤–ª–µ–Ω–æ'
        ],
        'sql_fields': [
            'id', 'hh_id', 'title', 'company', 'employer_id',
            'salary_from', 'salary_to', 'currency', 'experience', 'schedule',
            'employment', 'area', 'key_skills', 'published_at',
            'url', 'filter_id', 'content_hash', 'created_at', 'updated_at'
        ]
    },
    'analytical': {
        'name': '–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç',
        'description': '–° —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–ª–∞–≥–∏–Ω–æ–≤ –∏ –∞–Ω–∞–ª–∏–∑–∞',
        'columns': [
            '–ù–∞–∑–≤–∞–Ω–∏–µ', '–ö–æ–º–ø–∞–Ω–∏—è', '–ó–∞—Ä–ø–ª–∞—Ç–∞ –æ—Ç', '–ó–∞—Ä–ø–ª–∞—Ç–∞ –¥–æ', '–í–∞–ª—é—Ç–∞',
            '–û–ø—ã—Ç', '–ì–æ—Ä–æ–¥', '–ó–∞–Ω—è—Ç–æ—Å—Ç—å', '–ì—Ä–∞—Ñ–∏–∫',
            '–û–ø–∏—Å–∞–Ω–∏–µ', '–§–∏–ª—å—Ç—Ä', '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏', '–°—Å—ã–ª–∫–∞'
        ],
        'sql_fields': [
            'title', 'company', 'salary_from', 'salary_to', 'currency',
            'experience', 'area', 'employment', 'schedule',
            'description', 'filter_id', 'published_at', 'url'
        ]
    }
}


class VacancyExporter:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä –≤–∞–∫–∞–Ω—Å–∏–π –≤ Excel"""
    
    def __init__(self, db_path: str = "data/hh_v4.sqlite3"):
        self.db_path = db_path
        
        if not HAS_OPENPYXL:
            logger.error("openpyxl –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openpyxl")
            raise ImportError("openpyxl is required for Excel export")
    
    def export_to_excel(self, 
                       output_path: Union[str, Path],
                       format_type: str = 'brief',
                       limit: Optional[int] = None,
                       filters: Optional[Dict[str, Any]] = None,
                       include_description: bool = False) -> Dict[str, Any]:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –≤–∞–∫–∞–Ω—Å–∏–π –≤ Excel —Ñ–∞–π–ª
        
        Args:
            output_path: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
            format_type: –¢–∏–ø —Ñ–æ—Ä–º–∞—Ç–∞ ('brief', 'full', 'analytical')
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π (None = –≤—Å–µ)
            filters: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è SQL –∑–∞–ø—Ä–æ—Å–∞
            include_description: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–π (—É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä)
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞ (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞, –æ—à–∏–±–∫–∏)
        """
        logger.info(f"üöÄ –ù–∞—á–∞–ª–æ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ '{format_type}' –≤ —Ñ–∞–π–ª: {output_path}")
        
        start_time = datetime.now()
        result = {
            'success': False,
            'file_path': str(output_path),
            'format_type': format_type,
            'records_exported': 0,
            'file_size_mb': 0,
            'export_time_seconds': 0,
            'errors': []
        }
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç
            if format_type not in EXPORT_FORMATS:
                raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: {format_type}. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {list(EXPORT_FORMATS.keys())}")
            
            format_config = EXPORT_FORMATS[format_type]
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
            data = self._fetch_vacancy_data(format_config, limit, filters, include_description)
            
            if not data:
                logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
                result['errors'].append("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
                return result
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ DataFrame
            df = self._convert_to_dataframe(data, format_config)
            
            # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤ Excel
            self._write_to_excel(df, output_path, format_config)
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            output_file = Path(output_path)
            if output_file.exists():
                result.update({
                    'success': True,
                    'records_exported': len(df),
                    'file_size_mb': round(output_file.stat().st_size / (1024 * 1024), 2),
                    'export_time_seconds': round((datetime.now() - start_time).total_seconds(), 2)
                })
                
                logger.info(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: {result['records_exported']} –∑–∞–ø–∏—Å–µ–π, "
                           f"{result['file_size_mb']} –ú–ë, {result['export_time_seconds']} —Å–µ–∫")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}", exc_info=True)
            result['errors'].append(str(e))
        
        return result
    
    def _fetch_vacancy_data(self, 
                          format_config: Dict[str, Any], 
                          limit: Optional[int] = None,
                          filters: Optional[Dict[str, Any]] = None,
                          include_description: bool = False) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ –ë–î —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
        sql_fields = format_config['sql_fields'].copy()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if include_description and 'description' not in sql_fields:
            sql_fields.append('description')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º SQL –∑–∞–ø—Ä–æ—Å
        fields_str = ', '.join(sql_fields)
        base_query = f"SELECT {fields_str} FROM vacancies"
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        where_conditions = []
        params = []
        
        if filters:
            if 'date_from' in filters:
                where_conditions.append("created_at >= ?")
                params.append(filters['date_from'])
            if 'date_to' in filters:
                where_conditions.append("created_at <= ?")
                params.append(filters['date_to'])
            if 'min_salary' in filters:
                where_conditions.append("salary_from >= ?")
                params.append(filters['min_salary'])
            if 'area_name' in filters:
                where_conditions.append("area LIKE ?")
                params.append(f"%{filters['area_name']}%")
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        if where_conditions:
            base_query += " WHERE " + " AND ".join(where_conditions)
        
        base_query += " ORDER BY created_at DESC"
        
        if limit:
            base_query += f" LIMIT {limit}"
        
        logger.debug(f"SQL –∑–∞–ø—Ä–æ—Å: {base_query}")
        logger.debug(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {params}")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row  # –î–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–æ–ª–æ–Ω–∫–∞–º –ø–æ –∏–º–µ–Ω–∏
                cursor = conn.execute(base_query, params)
                rows = cursor.fetchall()
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
                data = [dict(row) for row in rows]
                
                logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π –∏–∑ –ë–î")
                return data
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è SQL –∑–∞–ø—Ä–æ—Å–∞: {e}")
            raise
    
    def _convert_to_dataframe(self, data: List[Dict[str, Any]], format_config: Dict[str, Any]) -> pd.DataFrame:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ DataFrame —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
        
        if not data:
            return pd.DataFrame()
        
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(data)
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ —Ñ–æ—Ä–º–∞—Ç—É
        if len(format_config['columns']) == len(format_config['sql_fields']):
            column_mapping = dict(zip(format_config['sql_fields'], format_config['columns']))
            df = df.rename(columns=column_mapping)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        for col in df.columns:
            if '–î–∞—Ç–∞' in col and col in df.columns:
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã
                df[col] = pd.to_datetime(df[col], errors='coerce').dt.strftime('%d.%m.%Y %H:%M')
            
            elif '–ö–ª—é—á–µ–≤—ã–µ –Ω–∞–≤—ã–∫–∏' in col and col in df.columns:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º JSON –Ω–∞–≤—ã–∫–∏
                df[col] = df[col].apply(self._format_skills)
            
            elif '–ó–∞—Ä–ø–ª–∞—Ç–∞' in col and col in df.columns:
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∑–∞—Ä–ø–ª–∞—Ç—ã
                df[col] = df[col].apply(lambda x: f"{int(x):,}".replace(',', ' ') if pd.notna(x) and x > 0 else '')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É "–°—Ç–∞—Ç—É—Å" –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        if '–°—Ç–∞—Ç—É—Å' not in df.columns:
            df['–°—Ç–∞—Ç—É—Å'] = ''
        
        logger.debug(f"DataFrame —Å–æ–∑–¥–∞–Ω: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")
        return df
    
    def _format_skills(self, skills_json: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ JSON"""
        if not skills_json:
            return ''
        
        try:
            if isinstance(skills_json, str):
                skills_list = json.loads(skills_json)
            else:
                skills_list = skills_json
            
            if isinstance(skills_list, list):
                return ', '.join(skills_list[:10])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 10 –Ω–∞–≤—ã–∫–∞–º–∏
            else:
                return str(skills_list)[:100]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                
        except (json.JSONDecodeError, TypeError):
            return str(skills_json)[:100] if skills_json else ''
    
    def _write_to_excel(self, df: pd.DataFrame, output_path: Union[str, Path], format_config: Dict[str, Any]):
        """–ó–∞–ø–∏—Å—å DataFrame –≤ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Excel —Ñ–∞–π–ª"""
        
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π ExcelWriter (–±–µ–∑ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö options)
        with pd.ExcelWriter(
            output_path,
            engine='openpyxl'
        ) as writer:
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ª–∏—Å—Ç
            sheet_name = f"–í–∞–∫–∞–Ω—Å–∏–∏_{format_config['name'].replace(' ', '_')}"
            df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            worksheet = writer.sheets[sheet_name]
            self._format_worksheet(worksheet, format_config)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏—Å—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± —ç–∫—Å–ø–æ—Ä—Ç–µ
            self._add_info_sheet(writer, df, format_config)
        
        logger.info(f"üìÅ –§–∞–π–ª Excel —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
    
    def _format_worksheet(self, worksheet, format_config: Dict[str, Any]):
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞ Excel (–Ω–∞ –æ—Å–Ω–æ–≤–µ format_worksheet –∏–∑ wh_logger_config.py)
        """
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–≤—Ç–æ—Ñ–∏–ª—å—Ç—Ä –∏ –∑–∞–∫—Ä–µ–ø–ª—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
        if worksheet.dimensions:
            worksheet.auto_filter.ref = worksheet.dimensions
            worksheet.freeze_panes = 'A2'
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç–∏–ª–∏
        base_alignment = Alignment(horizontal='left', vertical='top', wrap_text=False)
        header_font = Font(bold=True, color='FFFFFF')
        header_fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∏–ª–∏ –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —à–∏—Ä–∏–Ω—É –∫–æ–ª–æ–Ω–æ–∫
        max_lengths = [0] * (worksheet.max_column or 1)
        
        for row in worksheet.iter_rows():
            for cell in row:
                if cell.value:
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –±–∞–∑–æ–≤—ã–π —Å—Ç–∏–ª—å
                    cell.alignment = base_alignment
                    
                    if cell.row == 1:  # –ó–∞–≥–æ–ª–æ–≤–∫–∏
                        cell.font = header_font
                        cell.fill = header_fill
                        cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
                    
                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —à–∏—Ä–∏–Ω—É –∫–æ–ª–æ–Ω–∫–∏
                    try:
                        cell_length = len(str(cell.value))
                        if cell.column <= len(max_lengths):
                            max_lengths[cell.column - 1] = max(
                                max_lengths[cell.column - 1], 
                                min(cell_length, 50)  # –ú–∞–∫—Å–∏–º—É–º 50 —Å–∏–º–≤–æ–ª–æ–≤
                            )
                    except (IndexError, TypeError):
                        pass
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —à–∏—Ä–∏–Ω—É –∫–æ–ª–æ–Ω–æ–∫ (–æ—Ç 10 –¥–æ 40 —Å–∏–º–≤–æ–ª–æ–≤)
        for col, max_length in enumerate(max_lengths, 1):
            adjusted_width = max(min(max_length + 2, 40), 10)
            try:
                worksheet.column_dimensions[get_column_letter(col)].width = adjusted_width
            except Exception:
                pass
        
        logger.debug(f"–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {worksheet.max_row} —Å—Ç—Ä–æ–∫, {worksheet.max_column} –∫–æ–ª–æ–Ω–æ–∫")
    
    def _add_info_sheet(self, writer, df: pd.DataFrame, format_config: Dict[str, Any]):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –ª–∏—Å—Ç–∞"""
        
        info_data = {
            '–ü–∞—Ä–∞–º–µ—Ç—Ä': [
                '–§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞',
                '–û–ø–∏—Å–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞', 
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π',
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫',
                '–î–∞—Ç–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞',
                '–í—Ä–µ–º—è —ç–∫—Å–ø–æ—Ä—Ç–∞',
                '–ü—É—Ç—å –∫ –ë–î'
            ],
            '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                format_config['name'],
                format_config['description'],
                len(df),
                len(df.columns),
                datetime.now().strftime('%d.%m.%Y %H:%M:%S'),
                datetime.now().strftime('%H:%M:%S'),
                self.db_path
            ]
        }
        
        info_df = pd.DataFrame(info_data)
        info_df.to_excel(writer, sheet_name='–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è', index=False)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π –ª–∏—Å—Ç
        info_sheet = writer.sheets['–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è']
        info_sheet.column_dimensions['A'].width = 25
        info_sheet.column_dimensions['B'].width = 50
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏
        for cell in info_sheet[1]:
            cell.font = Font(bold=True)
            cell.fill = PatternFill(start_color='D9E1F2', end_color='D9E1F2', fill_type='solid')
    
    def get_export_formats(self) -> Dict[str, Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —ç–∫—Å–ø–æ—Ä—Ç–∞"""
        return EXPORT_FORMATS.copy()
    
    def get_vacancy_count(self, filters: Optional[Dict[str, Any]] = None) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞"""
        base_query = "SELECT COUNT(*) FROM vacancies"
        
        where_conditions = []
        params = []
        
        if filters:
            if 'date_from' in filters:
                where_conditions.append("created_at >= ?")
                params.append(filters['date_from'])
            if 'date_to' in filters:
                where_conditions.append("created_at <= ?")
                params.append(filters['date_to'])
            if 'min_salary' in filters:
                where_conditions.append("salary_from >= ?")
                params.append(filters['min_salary'])
        
        if where_conditions:
            base_query += " WHERE " + " AND ".join(where_conditions)
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute(base_query, params)
                count = cursor.fetchone()[0]
                return count
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–π: {e}")
            return 0


# // Chg_EXPORT_HELPER_2009: –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —ç–∫—Å–ø–æ—Ä—Ç–∞
def quick_export(output_path: Union[str, Path], 
                format_type: str = 'brief',
                limit: int = 1000,
                db_path: str = "data/hh_v4.sqlite3") -> Dict[str, Any]:
    """–ë—ã—Å—Ç—Ä—ã–π —ç–∫—Å–ø–æ—Ä—Ç —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
    exporter = VacancyExporter(db_path)
    return exporter.export_to_excel(output_path, format_type, limit)


def export_with_filters(output_path: Union[str, Path],
                       date_from: Optional[str] = None,
                       min_salary: Optional[int] = None,
                       area_name: Optional[str] = None,
                       format_type: str = 'brief') -> Dict[str, Any]:
    """–≠–∫—Å–ø–æ—Ä—Ç —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏"""
    filters = {}
    if date_from:
        filters['date_from'] = date_from
    if min_salary:
        filters['min_salary'] = min_salary
    if area_name:
        filters['area_name'] = area_name
    
    exporter = VacancyExporter()
    return exporter.export_to_excel(output_path, format_type, filters=filters)
